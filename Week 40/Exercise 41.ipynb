{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 41 - Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OLS REGRESSION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Plain GD with fixed learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import autograd.numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from random import random, seed\n",
    "from autograd import grad\n",
    "\n",
    "np.random.seed(2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Theta from own inversion: [[3.92107297]\n",
      " [3.94878834]\n",
      " [1.23008291]]\n",
      "Theta from GD: [[3.93072664]\n",
      " [3.89317344]\n",
      " [1.28332218]]\n"
     ]
    }
   ],
   "source": [
    "n = 100\n",
    "x = np.random.rand(n, 1)\n",
    "y = 4 + 3* x + 2*x**2 + np.random.randn(n, 1)\n",
    "X = np.c_[np.ones((n, 1)), x, x**2]\n",
    "\n",
    "XT_X = X.T @ X\n",
    "theta_linreg = np.linalg.inv(X.T @ X) @ (X.T @ y)\n",
    "print(\"Theta from own inversion OLS:\", theta_linreg)\n",
    "H = (2.0/n)*XT_X\n",
    "EigValues, EigVectors = np.linalg.eig(H)\n",
    "\n",
    "theta = np.random.randn(3, 1)\n",
    "eta = 1.0/np.max(EigValues)\n",
    "num_iter = 1000\n",
    "\n",
    "for iter in range(num_iter):\n",
    "    gradients = 2.0/n* X.T @ ((X @ theta) - y)\n",
    "    theta -= eta*gradients\n",
    "print(\"Theta from GD:\", theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Plain GD with fixed learning rate and momentum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Theta from GD with momentum: [[4.11202724]\n",
      " [2.95196881]\n",
      " [2.14193576]]\n"
     ]
    }
   ],
   "source": [
    "change = 0.0\n",
    "delta_momentum = 0.3\n",
    "\n",
    "for iter in range(num_iter):\n",
    "    gradients = 2.0/n* X.T @ ((X @ theta) - y)\n",
    "    new_change = eta*gradients + delta_momentum*change\n",
    "    theta -= new_change\n",
    "    change = new_change\n",
    "print(\"Theta from GD with momentum:\", theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparison:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Stochastic gradient descent "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Theta from SGD: [[4.2098165 ]\n",
      " [2.94005582]\n",
      " [2.14982706]]\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 100\n",
    "M = 5\n",
    "m = int(n/M)\n",
    "t0, t1 = 5, 50\n",
    "\n",
    "def learning_schedule(t):\n",
    "    return t0/(t+t1)\n",
    "\n",
    "theta = np.random.randn(3, 1)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i in range(m):\n",
    "        rand_index = M+np.random.randint(m)\n",
    "        x_i = X[rand_index:rand_index+M]\n",
    "        y_i = y[rand_index:rand_index+M]\n",
    "        gradients = (2.0/M)*x_i.T @ ((x_i @ theta) - y_i)\n",
    "        eta = learning_schedule(epoch*m + i)\n",
    "        theta -= eta*gradients\n",
    "print(\"Theta from SGD:\", theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discussion:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4a. Adagrad without and with momentum for GD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4a. Adagrad without and with momentum for SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. RMSprop and Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Theta from SGD with RMSprop: [[3.78533369]\n",
      " [3.53362961]\n",
      " [1.95202195]]\n"
     ]
    }
   ],
   "source": [
    "# RMSprop\n",
    "def CostOLS(y, X, theta):\n",
    "    return np.sum((y - X @ theta)**2)\n",
    "\n",
    "training_gradient = grad(CostOLS, 2)\n",
    "theta = np.random.randn(3, 1)\n",
    "num_epochs = 100\n",
    "M = 5\n",
    "m = int(n/M)\n",
    "eta = 0.01\n",
    "rho = 0.90\n",
    "delta = 1e-8\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    Giter = 0.0\n",
    "    for i in range(m):\n",
    "        rand_index = M+np.random.randint(m)\n",
    "        x_i = X[rand_index:rand_index+M]\n",
    "        y_i = y[rand_index:rand_index+M]\n",
    "        gradients = (1.0/M)*training_gradient(y_i, x_i, theta)\n",
    "        Giter = (rho*Giter + (1-rho)*gradients*gradients)\n",
    "        update = gradients*eta/(delta + np.sqrt(Giter))\n",
    "        theta -= update\n",
    "print(\"Theta from SGD with RMSprop:\", theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Theta from SGD with Adam: [[4.04005989]\n",
      " [2.9419719 ]\n",
      " [2.366378  ]]\n"
     ]
    }
   ],
   "source": [
    "# Adam\n",
    "training_gradient = grad(CostOLS, 2)\n",
    "theta = np.random.randn(3, 1)\n",
    "num_epochs = 100\n",
    "M = 5\n",
    "m = int(n/M)\n",
    "eta = 0.01\n",
    "beta1 = 0.9\n",
    "beta2 = 0.999\n",
    "delta = 1e-7\n",
    "\n",
    "iter = 0\n",
    "for epoch in range(num_epochs):\n",
    "    first_moment = 0.0\n",
    "    second_moment = 0.0\n",
    "    iter += 1\n",
    "    for i in range(m):\n",
    "        rand_index = M+np.random.randint(m)\n",
    "        x_i = X[rand_index:rand_index+M]\n",
    "        y_i = y[rand_index:rand_index+M]\n",
    "        gradients = (1.0/M)*training_gradient(y_i, x_i, theta)\n",
    "        first_moment = beta1*first_moment + (1-beta1)*gradients\n",
    "        second_moment = beta2*second_moment + (1-beta2)*gradients*gradients\n",
    "        first_term = first_moment/(1.0-beta1**iter)\n",
    "        second_term = second_moment/(1.0-beta2**iter)\n",
    "        update = eta*first_term/(np.sqrt(second_term)+delta)\n",
    "        theta -= update\n",
    "print(\"Theta from SGD with Adam:\", theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RIDGE REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Theta from own inversion Ridge: [[ 3.24671607]\n",
      " [ 6.53895183]\n",
      " [-1.01339229]]\n",
      "Theta from GD: [[ 3.34338792]\n",
      " [ 5.93070167]\n",
      " [-0.40819955]]\n",
      "Theta from own inversion Ridge: [[ 3.24817945]\n",
      " [ 6.52976414]\n",
      " [-1.004334  ]]\n",
      "Theta from GD: [[ 3.34463937]\n",
      " [ 5.9228277 ]\n",
      " [-0.40036532]]\n",
      "Theta from own inversion Ridge: [[ 3.25925695]\n",
      " [ 6.4602182 ]\n",
      " [-0.93578167]]\n",
      "Theta from GD: [[ 3.33416567]\n",
      " [ 5.98872691]\n",
      " [-0.46593195]]\n",
      "Theta from own inversion Ridge: [[ 3.33218031]\n",
      " [ 6.00254133]\n",
      " [-0.48537675]]\n",
      "Theta from GD: [[ 3.3290785 ]\n",
      " [ 6.02073475]\n",
      " [-0.49777824]]\n",
      "Theta from own inversion Ridge: [[3.57497191]\n",
      " [4.48200865]\n",
      " [0.989849  ]]\n",
      "Theta from GD: [[ 3.32059214]\n",
      " [ 6.07412988]\n",
      " [-0.5509039 ]]\n",
      "Theta from own inversion Ridge: [[3.77378748]\n",
      " [3.19813232]\n",
      " [2.01500249]]\n",
      "Theta from GD: [[ 3.33033688]\n",
      " [ 6.01281719]\n",
      " [-0.48990065]]\n",
      "Theta from own inversion Ridge: [[3.58538042]\n",
      " [2.41464775]\n",
      " [1.7710085 ]]\n",
      "Theta from GD: [[ 3.33237162]\n",
      " [ 6.00001489]\n",
      " [-0.47716295]]\n",
      "Theta from own inversion Ridge: [[1.98061782]\n",
      " [1.1931235 ]\n",
      " [0.87193815]]\n",
      "Theta from GD: [[ 3.34093263]\n",
      " [ 5.94615004]\n",
      " [-0.42356995]]\n",
      "Theta from own inversion Ridge: [[0.43085406]\n",
      " [0.2538397 ]\n",
      " [0.18489877]]\n",
      "Theta from GD: [[ 3.33852762]\n",
      " [ 5.96128207]\n",
      " [-0.43862561]]\n",
      "Theta from own inversion Ridge: [[0.06099372]\n",
      " [0.03582408]\n",
      " [0.0260813 ]]\n",
      "Theta from GD: [[ 3.3438985 ]\n",
      " [ 5.92748917]\n",
      " [-0.40500326]]\n"
     ]
    }
   ],
   "source": [
    "n = 100\n",
    "x = np.random.rand(n, 1)\n",
    "y = 4 + 3* x + 2*x**2 + np.random.randn(n, 1)\n",
    "X = np.c_[np.ones((n, 1)), x, x**2]\n",
    "lmb = np.logspace(-4, 4, 10)\n",
    "\n",
    "thetaa = np.zeros(len(lmb))\n",
    "etaa = np.zeros(len(lmb))\n",
    "XT_X = X.T @ X\n",
    "for j in range(len(lmb)):\n",
    "    theta_ridge = np.linalg.inv(X.T @ X + lmb[j]*np.eye(len(X.T))) @ (X.T @ y)\n",
    "    print(\"Theta from own inversion Ridge:\", theta_ridge)\n",
    "    H = (2.0/n)*XT_X\n",
    "    EigValues, EigVectors = np.linalg.eig(H)\n",
    "\n",
    "    theta = np.random.randn(3, 1)\n",
    "    eta = 1.0/np.max(EigValues)\n",
    "    num_iter = 1000\n",
    "\n",
    "    for iter in range(num_iter):\n",
    "        gradients = 2.0/n* X.T @ ((X @ theta) - y)\n",
    "        theta -= eta*gradients\n",
    "    print(\"Theta from GD:\", theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
